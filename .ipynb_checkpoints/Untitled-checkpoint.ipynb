{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_words(text):\n",
    "    words = text.split()\n",
    "    norm_words = []\n",
    "    for word in words:\n",
    "        lastChar = len(word) - 1 \n",
    "        if word[0] in (\"#\",\"@\",\"(\",\"$\",\"'\", '\"') or word[0].isdigit():\n",
    "            continue\n",
    "        if word[lastChar].isdigit() or (word[lastChar] in string.punctuation):\n",
    "            continue\n",
    "        norm_words.append(word.lower().rstrip(string.punctuation))\n",
    "    return norm_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fulltxt = []\n",
    "for x in range(85):\n",
    "    filename = '/data/federalist/' + str(x+1) + '.txt'\n",
    "    with open(filename, 'r') as myfile:\n",
    "        data = myfile.read().replace('\\n', ' ')\n",
    "        data = normalize_words(data)\n",
    "        \n",
    "    fulltxt = fulltxt + data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for word in fulltxt:\n",
    "    if word not in vocab:\n",
    "        vocab[word] = 1\n",
    "    else:\n",
    "        vocab[word] += 1\n",
    "df=pd.Series(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF=pd.DataFrame(columns=df.index)\n",
    "for x in range(85):\n",
    "    filename = '/data/federalist/' + str(x+1) + '.txt'\n",
    "    with open(filename, 'r') as myfile:\n",
    "        data = myfile.read().replace('\\n', ' ')\n",
    "        data = normalize_words(data)\n",
    "        \n",
    "    article = pd.DataFrame(columns = df.index)\n",
    "    article.loc[x] = 0\n",
    "    for word in data:\n",
    "        if word not in df.index:\n",
    "            continue\n",
    "        article[word] = article[word] + 1\n",
    "        \n",
    "    DF = DF.append(article)\n",
    "DF.index = range(1,len(DF)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors=pd.read_csv(\"/data/federalist/authorship.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors['index']=authors['Paper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge=pd.merge(DF.reset_index(),authors).set_index(\"index\")\n",
    "hamilton=merge.loc[merge['Author']==\"Hamilton\"].drop([\"Author\",'Paper'],axis=1)\n",
    "#hamilton=(hamilton.T/hamilton.T.sum(axis=0)).T\n",
    "jay=merge.loc[merge['Author']==\"Jay\"].drop([\"Author\",'Paper'],axis=1)\n",
    "#jay=(jay.T/jay.T.sum(axis=0)).T\n",
    "madison=merge.loc[merge['Author']==\"Madison\"].drop([\"Author\",'Paper'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Vary number of topics\n",
    "Calculate \"\"\"\n",
    "\"\"\"Loss function: sum over i and j of NIJ*logpij\n",
    "pijs from BA \"\"\"\n",
    "def doubleUpdate(numTopics,df):\n",
    "    ptd=[]\n",
    "    guess=[]\n",
    "    pwt=[]\n",
    "    for i in range(numTopics):\n",
    "        guess.append(1/numTopics)\n",
    "        pwt.append(np.random.dirichlet(range(df.shape[1]+1)))\n",
    "    for j in range(df.shape[0]):\n",
    "        ptd.append(guess)\n",
    "    ptd=pd.DataFrame(ptd)\n",
    "    ptd.index=df.index\n",
    "    pwt=pd.DataFrame(pwt).drop(0,axis=1)\n",
    "    pwt.columns=df.columns\n",
    "    #ptdnew=pd.DataFrame(0, columns=ptd.columns, index=ptd.index)\n",
    "    #pwtnew=pd.DataFrame(0, columns=df.columns,index=pwt.index)\n",
    "    i=0\n",
    "    AOLD=pd.DataFrame(0, columns=ptd.columns, index=ptd.index).T\n",
    "    A=ptd.T\n",
    "    B=pwt.T # document word\n",
    "    #return(A-AOLD)\n",
    "    #while(abs(((A-AOLD)).sum(axis=0).sum())>.0000001):\n",
    "    while(i<150):\n",
    "        i+=1\n",
    "        #print(i)\n",
    "        AOLD=A.copy()\n",
    "        BA=np.dot(B,A)\n",
    "        NBA=df.T/BA\n",
    "        BNBA=np.dot(B.T,NBA.fillna(0))\n",
    "        final1=A*BNBA\n",
    "        final1=pd.DataFrame(final1)/pd.DataFrame(final1).sum(axis=0)\n",
    "        A=final1\n",
    "        BA=np.dot(B,A)\n",
    "        NBA=df.T/BA\n",
    "        NBAA=np.dot(NBA.fillna(0),A.T)\n",
    "        final2=B*NBAA\n",
    "        final2=pd.DataFrame(final2)/pd.DataFrame(final2).sum(axis=0)\n",
    "        B=final2\n",
    "        #print((A-AOLD).sum(axis=0).sum())\n",
    "        #print(A[1])\n",
    "    return(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamilton1=doubleUpdate(5,hamilton)\n",
    "madison1=doubleUpdate(5,madison)\n",
    "jay1=doubleUpdate(5,jay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamilton1[1].columns=[\"Hamilton\"+str(i+1) for i in hamilton1[1].columns]\n",
    "madison1[1].columns=[\"Madison\"+str(i+1) for i in madison1[1].columns]\n",
    "jay1[1].columns=[\"Jay\"+str(i+1) for i in jay1[1].columns]\n",
    "allTopics=hamilton1[1].T.append(jay1[1].T).append(madison1[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 7969)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTopics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of the EM algorithim for a Poisson distribution with 3 potential authors.\n",
    "Can be expanded for different lengths.\n",
    "Assumes document has filtered out all column values that do not appear. \n",
    "\"\"\"\n",
    "def EM_Algo(guess,pwapass,documentpass):\n",
    "    #print(\"start\")\n",
    "    newguess=[]\n",
    "    for i in range(pwapass.shape[0]):\n",
    "        newguess.append(0)\n",
    "    newguess=pd.DataFrame(newguess).T\n",
    "    j=0\n",
    "    pwapass=pwapass[documentpass.index.tolist()]\n",
    "    #while (abs(newguess[0]-guess[0])+abs(newguess[1]-guess[1])+abs(newguess[2]-guess[2]))[0]>.0001: \n",
    "    while j<50:\n",
    "        #print(\"enter\")\n",
    "        \n",
    "        if j!=0:\n",
    "            guess=newguess.copy()\n",
    "            j+=1\n",
    "        j+=1\n",
    "        print(j)\n",
    "        #print(newguess.shape)\n",
    "        unnormalized=[]\n",
    "        paw=[]\n",
    "        for i in range(newguess.shape[1]):\n",
    "            passed=guess[i]\n",
    "            if j!=1:\n",
    "                guess=guess[0]\n",
    "            oneside=np.dot(guess[i],pd.DataFrame(pwapass.iloc[i,:]).T)\n",
    "            #print(\"LENGTH\"+str(len(oneside[0])))\n",
    "            paw.append(oneside[0])\n",
    "        print(pd.DataFrame(paw).shape)\n",
    "        for i in range(len(paw[0])):\n",
    "            s=[paw[j][i] for j in range(len(newguess))]\n",
    "            s=sum(s)\n",
    "            for k in range(len(newguess)):\n",
    "                paw[k][i]=paw[k][i]/s\n",
    "        print(pd.DataFrame(paw).shape)\n",
    "        newguess=[np.dot(np.nan_to_num(i),pd.DataFrame(documentpass)) for i in paw]\n",
    "        newguess=[i/sum(newguess) for i in newguess]\n",
    "        newguess=[i.tolist()[0] for i in newguess]\n",
    "        newguess=pd.DataFrame(pd.Series(newguess)).T\n",
    "    return(newguess)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guess=[1/allTopics.shape[0] for i in range(allTopics.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EM_Algo(guess,allTopics,DF.iloc[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a               29.0\n",
       "abandon          0.0\n",
       "abandoned        0.0\n",
       "abandoning       0.0\n",
       "abate            0.0\n",
       "abbe             0.0\n",
       "abetted          0.0\n",
       "abhorrence       0.0\n",
       "abilities        0.0\n",
       "ability          0.0\n",
       "abject           0.0\n",
       "able             0.0\n",
       "ablest           0.0\n",
       "abolish          0.0\n",
       "abolished        0.0\n",
       "abolishing       0.0\n",
       "abolition        0.0\n",
       "abounding        0.0\n",
       "abounds          0.0\n",
       "about            0.0\n",
       "above            0.0\n",
       "abraham          0.0\n",
       "abridge          0.0\n",
       "abridged         0.0\n",
       "abridgements     0.0\n",
       "abridging        0.0\n",
       "abridgment       0.0\n",
       "abroad           0.0\n",
       "abrogate         0.0\n",
       "abrogating       0.0\n",
       "                ... \n",
       "worthy           2.0\n",
       "would            5.0\n",
       "wound            0.0\n",
       "wounded          0.0\n",
       "wreaked          0.0\n",
       "wreck            0.0\n",
       "wrest            0.0\n",
       "wretched         0.0\n",
       "writ             0.0\n",
       "writer           0.0\n",
       "writers          0.0\n",
       "writings         0.0\n",
       "written          0.0\n",
       "wrong            0.0\n",
       "wrongs           0.0\n",
       "wrought          1.0\n",
       "xiv              0.0\n",
       "year             0.0\n",
       "years            0.0\n",
       "yet              3.0\n",
       "yield            0.0\n",
       "yielding         0.0\n",
       "yoke             0.0\n",
       "york             0.0\n",
       "you              0.0\n",
       "young            0.0\n",
       "your             0.0\n",
       "zaleucus         0.0\n",
       "zeal             0.0\n",
       "zealous          0.0\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
